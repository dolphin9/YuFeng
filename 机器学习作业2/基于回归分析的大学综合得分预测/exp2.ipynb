{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exp2：基于回归分析的大学综合得分预测\n",
    "---\n",
    "\n",
    "## 一、案例简介\n",
    "大学排名是一个非常重要同时也极富挑战性与争议性的问题，一所大学的综合实力涉及科研、师资、学生等方方面面。目前全球有上百家评估机构会评估大学的综合得分进行排序，而这些机构的打分也往往并不一致。在这些评分机构中，世界大学排名中心（Center for World University Rankings，缩写CWUR）以评估教育质量、校友就业、研究成果和引用，而非依赖于调查和大学所提交的数据著称，是非常有影响力的一个。\n",
    "\n",
    "本任务中我们将根据 CWUR 所提供的世界各地知名大学各方面的排名（师资、科研等），一方面通过数据可视化的方式观察不同大学的特点，另一方面希望构建机器学习模型（线性回归）预测一所大学的综合得分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、作业说明\n",
    "使用来自 Kaggle 的[数据](https://www.kaggle.com/mylesoneill/world-university-rankings?select=cwurData.csv)，构建「线性回归」模型，根据大学各项指标的排名预测综合得分。\n",
    "\n",
    "**基本要求：**\n",
    "* 按照 8:2 随机划分训练集测试集，用 RMSE 作为评价指标，得到测试集上线性回归模型的 RMSE 值；\n",
    "* 对线性回归模型的系数进行分析。\n",
    "\n",
    "**扩展要求：**\n",
    "* 对数据进行观察与可视化，展示数据特点；\n",
    "* 尝试其他的回归模型，对比效果；\n",
    "* 尝试将离散的地区特征融入线性回归模型，并对结果进行对比。\n",
    "\n",
    "**注意事项：**\n",
    "* 基本输入特征有 8 个：`quality_of_education`, `alumni_employment`, `quality_of_faculty`, `publications`, `influence`, `citations`, `broad_impact`, `patents`；\n",
    "* 预测目标为`score`；\n",
    "* 可以使用 sklearn 等第三方库，不要求自己实现线性回归；\n",
    "* 需要保留所有数据集生成、模型训练测试的代码；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、数据概览"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设数据文件位于当前文件夹，我们用 pandas 读入标准 csv 格式文件的函数`read_csv()`将数据转换为`DataFrame`的形式。观察前几条数据记录："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>world_rank</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>institution</th>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Stanford University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national_rank</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_of_education</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alumni_employment</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality_of_faculty</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publications</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>influence</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citations</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broad_impact</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patents</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>100.0</td>\n",
       "      <td>91.67</td>\n",
       "      <td>89.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0  \\\n",
       "world_rank                             1   \n",
       "institution           Harvard University   \n",
       "region                               USA   \n",
       "national_rank                          1   \n",
       "quality_of_education                   7   \n",
       "alumni_employment                      9   \n",
       "quality_of_faculty                     1   \n",
       "publications                           1   \n",
       "influence                              1   \n",
       "citations                              1   \n",
       "broad_impact                         NaN   \n",
       "patents                                5   \n",
       "score                              100.0   \n",
       "year                                2012   \n",
       "\n",
       "                                                          1  \\\n",
       "world_rank                                                2   \n",
       "institution           Massachusetts Institute of Technology   \n",
       "region                                                  USA   \n",
       "national_rank                                             2   \n",
       "quality_of_education                                      9   \n",
       "alumni_employment                                        17   \n",
       "quality_of_faculty                                        3   \n",
       "publications                                             12   \n",
       "influence                                                 4   \n",
       "citations                                                 4   \n",
       "broad_impact                                            NaN   \n",
       "patents                                                   1   \n",
       "score                                                 91.67   \n",
       "year                                                   2012   \n",
       "\n",
       "                                        2  \n",
       "world_rank                              3  \n",
       "institution           Stanford University  \n",
       "region                                USA  \n",
       "national_rank                           3  \n",
       "quality_of_education                   17  \n",
       "alumni_employment                      11  \n",
       "quality_of_faculty                      5  \n",
       "publications                            4  \n",
       "influence                               2  \n",
       "citations                               2  \n",
       "broad_impact                          NaN  \n",
       "patents                                15  \n",
       "score                                89.5  \n",
       "year                                 2012  "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_df = pd.read_csv('./cwurData.csv')  # 读入 csv 文件为 pandas 的 DataFrame\n",
    "data_df.head(3).T  # 观察前几列并转置方便观察"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除其中包含 NaN 的数据，保留 2000 条有效记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df.dropna()  # 舍去包含 NaN 的 row\n",
    "len(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取出对应自变量以及因变量的列，之后就可以基于此切分训练集和测试集，并进行模型构建与分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_of_faculty</th>\n",
       "      <th>publications</th>\n",
       "      <th>citations</th>\n",
       "      <th>alumni_employment</th>\n",
       "      <th>influence</th>\n",
       "      <th>quality_of_education</th>\n",
       "      <th>broad_impact</th>\n",
       "      <th>patents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>218</td>\n",
       "      <td>926</td>\n",
       "      <td>812</td>\n",
       "      <td>567</td>\n",
       "      <td>845</td>\n",
       "      <td>367</td>\n",
       "      <td>969.0</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>218</td>\n",
       "      <td>997</td>\n",
       "      <td>645</td>\n",
       "      <td>566</td>\n",
       "      <td>908</td>\n",
       "      <td>236</td>\n",
       "      <td>981.0</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>218</td>\n",
       "      <td>830</td>\n",
       "      <td>812</td>\n",
       "      <td>549</td>\n",
       "      <td>823</td>\n",
       "      <td>367</td>\n",
       "      <td>975.0</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>218</td>\n",
       "      <td>886</td>\n",
       "      <td>812</td>\n",
       "      <td>567</td>\n",
       "      <td>974</td>\n",
       "      <td>367</td>\n",
       "      <td>975.0</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>218</td>\n",
       "      <td>861</td>\n",
       "      <td>812</td>\n",
       "      <td>567</td>\n",
       "      <td>991</td>\n",
       "      <td>367</td>\n",
       "      <td>981.0</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      quality_of_faculty  publications  citations  alumni_employment  \\\n",
       "200                    1             1          1                  1   \n",
       "201                    4             5          3                  2   \n",
       "202                    2            15          2                 11   \n",
       "203                    5            10         12                 10   \n",
       "204                   10            11         11                 12   \n",
       "...                  ...           ...        ...                ...   \n",
       "2195                 218           926        812                567   \n",
       "2196                 218           997        645                566   \n",
       "2197                 218           830        812                549   \n",
       "2198                 218           886        812                567   \n",
       "2199                 218           861        812                567   \n",
       "\n",
       "      influence  quality_of_education  broad_impact  patents  \n",
       "200           1                     1           1.0        2  \n",
       "201           3                    11           4.0        6  \n",
       "202           2                     3           2.0        1  \n",
       "203           9                     2          13.0       48  \n",
       "204          12                     7          12.0       16  \n",
       "...         ...                   ...           ...      ...  \n",
       "2195        845                   367         969.0      816  \n",
       "2196        908                   236         981.0      871  \n",
       "2197        823                   367         975.0      824  \n",
       "2198        974                   367         975.0      651  \n",
       "2199        991                   367         981.0      547  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['quality_of_faculty', 'publications', 'citations', 'alumni_employment', \n",
    "                'influence', 'quality_of_education', 'broad_impact', 'patents']\n",
    "X = data_df[feature_cols]\n",
    "Y = data_df['score']\n",
    "print(type(X))\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（待完成）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型按8：2划分数据集和训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000,), (2000, 8), (1600, 8), (400, 8), (1600,), (400,))"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "all_y = Y.values\n",
    "all_x = X.values\n",
    "#print(type(all_y))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_x, all_y, test_size = 0.2, random_state = 2022)\n",
    "\n",
    "all_y.shape, all_x.shape, x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用最小二乘法求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用pytorch将数据转换成tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[210., 653., 310.,  ..., 355., 596., 637.],\n",
       "         [218., 971., 812.,  ..., 367., 837., 416.],\n",
       "         [210., 896., 609.,  ..., 355., 897., 121.],\n",
       "         ...,\n",
       "         [210., 292., 406.,  ..., 355., 415.,  28.],\n",
       "         [218., 353., 287.,  ..., 367., 318.,  60.],\n",
       "         [210., 785., 800.,  ..., 355., 897., 737.]], dtype=torch.float64),\n",
       " tensor([45.7400, 44.1700, 44.8200,  ..., 48.6300, 46.5900, 44.4000],\n",
       "        dtype=torch.float64),\n",
       " tensor([  5.5845,   1.1618,   2.2255,  ..., 100.4841,  13.0658,   1.4623],\n",
       "        dtype=torch.float64),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x_tensor = torch.tensor(x_train,dtype=torch.double)\n",
    "y_tensor = torch.tensor(y_train, dtype = torch.double)\n",
    "lable = torch.exp(y_tensor + torch.ones(y_tensor.shape) * (0 - y_tensor.min()))\n",
    "\n",
    "e_tensor = torch.ones([x_tensor.shape[0],1]) # 生成[1600,1]的标准矩阵\n",
    "x_tensor,y_tensor, lable, e_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[210., 653., 310.,  ..., 596., 637.,   1.],\n",
       "        [218., 971., 812.,  ..., 837., 416.,   1.],\n",
       "        [210., 896., 609.,  ..., 897., 121.,   1.],\n",
       "        ...,\n",
       "        [210., 292., 406.,  ..., 415.,  28.,   1.],\n",
       "        [218., 353., 287.,  ..., 318.,  60.,   1.],\n",
       "        [210., 785., 800.,  ..., 897., 737.,   1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = torch.cat((x_tensor,e_tensor), 1) #链接偏移量与x（特征）矩阵\n",
    "feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据公式求出权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([-2.7595e+20], dtype=torch.float64), tensor([7.1937e+18], dtype=torch.float64), tensor([5.2635e+18], dtype=torch.float64), tensor([-2.6534e+19], dtype=torch.float64), tensor([8.7693e+18], dtype=torch.float64), tensor([-9.6745e+18], dtype=torch.float64), tensor([-4.4543e+18], dtype=torch.float64), tensor([-5.3604e+18], dtype=torch.float64), tensor([6.4334e+22], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "b_pre = torch.mm(torch.mm(torch.inverse(torch.mm(torch.t(feature),feature)),torch.t(feature)),lable.view(1600,1))\n",
    "print(list(b_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将测试数据转换为矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[140.,   3.,   6.,  ...,  14.,  12.,   1.],\n",
       "         [218., 236., 368.,  ..., 265., 797.,   1.],\n",
       "         [210., 943., 406.,  ..., 703., 204.,   1.],\n",
       "         ...,\n",
       "         [218., 887., 645.,  ..., 781., 839.,   1.],\n",
       "         [218., 225., 321.,  ..., 262., 443.,   1.],\n",
       "         [140., 165., 283.,  ..., 176., 373.,   1.]], dtype=torch.float64),\n",
       " tensor([[51.5780],\n",
       "         [    nan],\n",
       "         [48.4016],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.7454],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.3573],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.3888],\n",
       "         [43.9595],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [52.4276],\n",
       "         [49.8844],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [52.4690],\n",
       "         [48.7683],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.5139],\n",
       "         [52.2438],\n",
       "         [49.8043],\n",
       "         [52.4817],\n",
       "         [49.4933],\n",
       "         [    nan],\n",
       "         [51.8460],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.8718],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.4615],\n",
       "         [51.9869],\n",
       "         [49.1543],\n",
       "         [47.6149],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.8199],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.2777],\n",
       "         [    nan],\n",
       "         [48.1621],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.3658],\n",
       "         [    nan],\n",
       "         [52.3849],\n",
       "         [50.1002],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.0413],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.5052],\n",
       "         [    nan],\n",
       "         [51.9039],\n",
       "         [51.7723],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.9552],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.9557],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.1083],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.8762],\n",
       "         [50.4604],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [47.7585],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.9145],\n",
       "         [50.5340],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [47.0765],\n",
       "         [    nan],\n",
       "         [51.2824],\n",
       "         [51.9756],\n",
       "         [    nan],\n",
       "         [49.8745],\n",
       "         [49.3667],\n",
       "         [48.9704],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.4443],\n",
       "         [49.3232],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.2003],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.9569],\n",
       "         [    nan],\n",
       "         [48.7552],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.2988],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [52.4765],\n",
       "         [    nan],\n",
       "         [50.4070],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.8023],\n",
       "         [    nan],\n",
       "         [45.1257],\n",
       "         [    nan],\n",
       "         [49.7509],\n",
       "         [47.3812],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.1320],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.3349],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.9012],\n",
       "         [49.7109],\n",
       "         [    nan],\n",
       "         [52.1252],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [52.2964],\n",
       "         [51.9609],\n",
       "         [52.2864],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.2816],\n",
       "         [48.7061],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.1248],\n",
       "         [    nan],\n",
       "         [51.1615],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.2588],\n",
       "         [    nan],\n",
       "         [52.1602],\n",
       "         [49.1821],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.4181],\n",
       "         [    nan],\n",
       "         [52.0885],\n",
       "         [48.0868],\n",
       "         [52.0827],\n",
       "         [    nan],\n",
       "         [50.5435],\n",
       "         [52.2275],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.9120],\n",
       "         [50.0356],\n",
       "         [    nan],\n",
       "         [51.7243],\n",
       "         [51.7707],\n",
       "         [    nan],\n",
       "         [51.0082],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.2423],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.4296],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.4804],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.6191],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.9173],\n",
       "         [50.9034],\n",
       "         [    nan],\n",
       "         [50.0080],\n",
       "         [    nan],\n",
       "         [52.2315],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.9189],\n",
       "         [50.9631],\n",
       "         [    nan],\n",
       "         [50.0356],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.3722],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.1743],\n",
       "         [49.1665],\n",
       "         [47.9219],\n",
       "         [49.6659],\n",
       "         [49.0326],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.7819],\n",
       "         [    nan],\n",
       "         [47.5361],\n",
       "         [49.5695],\n",
       "         [50.1418],\n",
       "         [52.1608],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.7189],\n",
       "         [48.8146],\n",
       "         [    nan],\n",
       "         [52.1317],\n",
       "         [    nan],\n",
       "         [51.7322],\n",
       "         [    nan],\n",
       "         [51.4756],\n",
       "         [49.2226],\n",
       "         [    nan],\n",
       "         [48.6609],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.4818],\n",
       "         [52.4671],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [52.3861],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.4490],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.3981],\n",
       "         [51.0905],\n",
       "         [51.9066],\n",
       "         [50.6902],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [47.0069],\n",
       "         [50.4499],\n",
       "         [49.3317],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.4931],\n",
       "         [52.1755],\n",
       "         [48.5007],\n",
       "         [51.2356],\n",
       "         [    nan],\n",
       "         [50.7273],\n",
       "         [52.1990],\n",
       "         [52.1179],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.5260],\n",
       "         [47.6892],\n",
       "         [49.8119],\n",
       "         [    nan],\n",
       "         [51.6788],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.3226],\n",
       "         [47.1463],\n",
       "         [50.2430],\n",
       "         [48.8632],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [50.5962],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.3863],\n",
       "         [    nan],\n",
       "         [49.4230],\n",
       "         [52.2568],\n",
       "         [49.3990],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [52.3961],\n",
       "         [52.3524],\n",
       "         [49.8346],\n",
       "         [    nan],\n",
       "         [51.2520],\n",
       "         [52.0663],\n",
       "         [50.6171],\n",
       "         [49.2769],\n",
       "         [48.4978],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.7786],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [52.0316],\n",
       "         [    nan],\n",
       "         [52.4907],\n",
       "         [49.1595],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [48.9498],\n",
       "         [    nan],\n",
       "         [52.2134],\n",
       "         [49.3750],\n",
       "         [    nan],\n",
       "         [46.4812],\n",
       "         [    nan],\n",
       "         [50.9465],\n",
       "         [49.0344],\n",
       "         [    nan],\n",
       "         [49.6942],\n",
       "         [51.6708],\n",
       "         [50.4822],\n",
       "         [50.7572],\n",
       "         [52.5066],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [49.2771],\n",
       "         [49.7476],\n",
       "         [51.8461],\n",
       "         [    nan],\n",
       "         [49.4158],\n",
       "         [50.4077],\n",
       "         [    nan],\n",
       "         [    nan],\n",
       "         [51.0974]], dtype=torch.float64))"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_tensor = torch.tensor(x_test, dtype=torch.double)\n",
    "test_e_tensor = torch.ones(test_x_tensor.shape[0]).view([len(test_x_tensor),1])\n",
    "test_feature = torch.cat((test_x_tensor,test_e_tensor),1)\n",
    "test_ans = torch.log(torch.mm(test_feature,b_pre))\n",
    "test_feature,  test_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1320e+47]], dtype=torch.float64)"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.tensor(y_test).view([400,1]) - test_ans\n",
    "loss = torch.mm(torch.t(loss),loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算RMSE（均方根误差）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.411269648507298e+21"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = (loss.item()/len(lable))**0.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算 $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.4802070803207813e+42"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = (torch.tensor(y_test)- torch.mean(torch.tensor(y_test))).view([-1,1])\n",
    "var = torch.mm(torch.t(var),var)\n",
    "R = 1-loss.item()/var.item()\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from scipy.linalg import expm,logm\n",
    "x = y_test\n",
    "y = torch.log(test_ans)\n",
    "plt.xlabel(\"y_pre\")\n",
    "plt.ylabel(\"y_test\")\n",
    "plt.plot(x,y,\"ob\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "91937119f9e03c68e578ef19ac47c21da02b60366121cf795fb85c8039e2d91a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
